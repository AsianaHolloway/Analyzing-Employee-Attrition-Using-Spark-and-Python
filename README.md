# 📊 Analyzing Employee Attrition Using Spark and Python

## Project Overview

Employee attrition can reveal hidden issues in a workplace—from poor job satisfaction to work-life balance challenges. This project aims to uncover key factors that influence employee turnover using **PySpark** and a **linear regression model**. Built as part of my graduate coursework in **Big Data Analytics**, it demonstrates my ability to set up a dual-node Spark environment, perform data preprocessing, and extract meaningful insights from large datasets.

---

## 👨‍💻 Tools & Technologies

- **Apache Spark** (with dual-VM cluster: Hadoop1 as NameNode, Hadoop2 as DataNode)
- **PySpark** for distributed data processing
- **Pandas** & **Matplotlib** for visualization
- **Scikit-learn** for regression modeling

---

## 🗂 Dataset

- **IBM HR Analytics Employee Attrition Dataset**  
  📥 [View Dataset on Kaggle](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)  
  Records: 1,470+ employee profiles including fields like:
  - Age
  - Job Role
  - Monthly Income
  - Work-Life Balance
  - Job Satisfaction
  - Attrition Status

---

## 🔍 Objectives

- ✅ Preprocess and clean data (remove missing values, label encode categories)
- ✅ Load dataset into Spark DataFrames using PySpark
- ✅ Analyze key variables using linear regression
- ✅ Visualize attrition counts using Pandas & Matplotlib
- ✅ Compare single-VM vs. dual-VM Spark performance

---

## 📈 Key Insights

- Identified correlations between **Monthly Income**, **Job Satisfaction**, and **Attrition**
- Regression modeling revealed key predictive features of employee turnover
- Data visualization clearly illustrated attrition patterns
- Running Spark in a dual-VM setup improved processing efficiency and memory usage

---

## 📷 Screenshots

- 💻 Dual-node Spark Setup
- 📊 Employee Attrition Bar Chart
- 🧹 Data Cleaning in PySpark

---

## 🧠 What I Learned

This project helped me:
- Set up and configure Spark in a virtual cluster
- Apply machine learning techniques to real-world HR data
- Use PySpark to process and analyze large datasets
- Translate insights into meaningful business recommendations

---

## 📂 Files Included

- `project_proposal.docx`: Initial planning and project scope
- `employee_analysis_report.docx`: Final analysis write-up
- `code/`: Spark and Python scripts
- `visuals/`: Screenshot folder (Spark setup, bar chart)
- `README.md`: Project summary and references

---

## 🔗 Additional Resources

- 🗃️ [Kaggle Dataset](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset)  
- 📄 [Final Project Report (Google Drive)](https://drive.google.com/file/d/1IVZsBk37MifbOHTgSiFh0dqButzFqaV9/view?usp=drive_link)

---



